## Вступление: Что такое информация и зачем её кодировать?

Представьте, что вы хотите отправить другу письмо. Вы можете написать его на русском языке, можете зашифровать его секретным кодом, можете сократить текст, используя аббревиатуры, или можете даже нарисовать картинки вместо слов. Всё это — разные способы **кодирования** одной и той же информации.

В компьютерном мире кодирование — это процесс преобразования информации из одной формы в другую. Это не просто техническая процедура, а целая наука, которая помогает нам решать три главные задачи:

1. **Экономить место** — сжимать большие файлы, чтобы они занимали меньше памяти
2. **Защищать от ошибок** — делать так, чтобы даже если часть данных потеряется при передаче, мы смогли их восстановить
3. **Обеспечивать безопасность** — шифровать информацию, чтобы только нужные люди могли её прочитать

Давайте разберёмся во всём этом подробно, начиная с самых основ.

***

## Глава 1: Основы теории информации

### 1.1 Что такое информация с точки зрения математики?

Когда вы подбрасываете монету, она может упасть либо орлом, либо решкой. Это событие несёт в себе информацию. Но сколько именно информации? Для ответа на этот вопрос математики придумали специальную меру — **бит**.

**Бит** — это количество информации, которое мы получаем, когда выбираем между двумя равновероятными вариантами. Одно подбрасывание монеты даёт нам ровно 1 бит информации.

Если вариантов больше, то и информации больше. Например, если вы бросаете кубик (6 граней), то получаете больше информации, чем от монеты. Но как это измерить?

### 1.2 Энтропия: мера неопределённости

Клод Шеннон — отец теории информации — придумал формулу для измерения количества информации. Он назвал эту меру **энтропией**.

Представьте, что у нас есть источник информации, который выдаёт разные символы с разными вероятностями. Например, в русском языке буква "о" встречается чаще, чем буква "ъ". Энтропия показывает, сколько информации в среднем несёт один символ от этого источника.

**Математическая формула энтропии:**

$$
H = -\sum_{i=1}^{n} p_i \log_2 p_i
$$

Где:

- $H$ — энтропия (измеряется в битах на символ)
- $p_i$ — вероятность появления $i$-го символа
- $n$ — количество различных символов
- $\log_2$ — логарифм по основанию 2

**Давайте разберём простой пример:**

Предположим, у нас есть источник, который выдаёт только два символа: A и B.

- Символ A появляется с вероятностью 0.75 (75% случаев)
- Символ B появляется с вероятностью 0.25 (25% случаев)

Рассчитаем энтропию:

$$
H = -(0.75 \times \log_2 0.75 + 0.25 \times \log_2 0.25)
$$

$$
H = -(0.75 \times (-0.415) + 0.25 \times (-2))
$$

$$
H = -(-0.311 - 0.5) = 0.811 \text{ бит/символ}
$$

**Что это означает?** Это означает, что в среднем каждый символ из этого источника несёт примерно 0.811 бит информации. Это меньше 1 бита, потому что символы появляются неравномерно — мы можем частично "предугадать" следующий символ (скорее всего, это будет A).

**Важное свойство энтропии:** Энтропия максимальна, когда все символы равновероятны. Для двух символов максимальная энтропия равна 1 биту (когда оба символа появляются с вероятностью 0.5).

### 1.3 Избыточность информации

Теперь важный момент: **избыточность**. Это разница между тем, сколько места реально занимает наша информация, и тем минимумом, который определяется энтропией.

Если мы кодируем каждый символ фиксированным количеством бит (например, каждый символ = 1 бит), но энтропия источника меньше 1 бита на символ, то мы тратим место впустую. Эта "лишняя" часть и есть избыточность.

**Формула избыточности:**

$$
R = 1 - \frac{H}{L}
$$

Где:

- $R$ — избыточность (от 0 до 1)
- $H$ — энтропия источника
- $L$ — средняя длина кодового слова

Например, если энтропия = 0.811 бит/символ, а мы используем по 1 биту на символ:

$$
R = 1 - \frac{0.811}{1} = 0.189 \text{ или } 18.9\%
$$

Это значит, что 18.9% нашего кода — избыточность, которую можно убрать с помощью **сжатия**.

***

## Глава 2: Виды кодирования — общая классификация

Теперь, когда мы понимаем основы теории информации, давайте рассмотрим, какие бывают виды кодирования. Их можно разделить на несколько больших категорий в зависимости от целей:

### 2.1 Эффективное (статическое, энтропийное) кодирование

**Цель:** Уменьшить размер данных, убрав избыточность, при этом не потеряв ни единого бита информации.

**Принцип:** Часто встречающиеся символы кодируются короткими кодами, редкие — длинными.

**Примеры алгоритмов:**

- Кодирование Хаффмана
- Арифметическое кодирование
- Кодирование Шеннона-Фано

**Аналогия:** Представьте, что вы записываете разговор. Вместо того чтобы каждый раз писать слово "например" полностью, вы используете сокращение "напр." — так экономится место, но информация не теряется.

### 2.2 Помехоустойчивое кодирование

**Цель:** Защитить информацию от искажений при передаче по ненадёжному каналу связи.

**Принцип:** Добавляются специальные "проверочные" биты, которые позволяют обнаружить и исправить ошибки.

**Примеры алгоритмов:**

- Коды Хэмминга
- Коды Рида-Соломона
- Циклические коды (БЧХ)

**Аналогия:** Когда вы диктуете по телефону важную информацию, вы можете сказать: "Буква А, как Анна" — это избыточная информация, которая помогает собеседнику правильно вас понять, даже если связь плохая.

### 2.3 Криптографическое кодирование (шифрование)

**Цель:** Скрыть содержание информации от посторонних глаз.

**Принцип:** Данные преобразуются таким образом, что без специального ключа их невозможно прочитать.

**Примеры алгоритмов:**

- AES (Advanced Encryption Standard)
- RSA (асимметричное шифрование)
- DES (старый стандарт)

**Аналогия:** Это как писать письмо на секретном языке, который знаете только вы и ваш друг.

### 2.4 Кодирование с потерями

**Цель:** Радикально уменьшить размер данных, допустив некоторые (незаметные для человека) искажения.

**Принцип:** Удаляются "несущественные" детали, которые человек всё равно не заметит.

**Примеры алгоритмов:**

- JPEG (для изображений)
- MP3 (для аудио)
- MPEG, H.264 (для видео)

**Аналогия:** Когда художник рисует портрет, он не прорисовывает каждую пору на коже — он передаёт общее впечатление, и этого достаточно.

### 2.5 Словарное кодирование

**Цель:** Сжатие данных путём замены повторяющихся последовательностей ссылками на них.

**Принцип:** Алгоритм "запоминает" уже встреченные фрагменты и при повторении заменяет их короткими ссылками.

**Примеры алгоритмов:**

- LZ77, LZ78, LZW
- DEFLATE (используется в ZIP)

**Аналогия:** Представьте, что в книге часто встречается длинная фраза "Российская Федерация". После первого упоминания вы можете писать просто "РФ" — так экономится место.

***

## Глава 3: Статические методы беспотерьного сжатия

Теперь подробно разберём каждый метод с теорией, примерами и реализацией на C++.

### 3.1 Кодирование длин серий (RLE — Run-Length Encoding)

#### Теория

RLE — это самый простой алгоритм сжатия. Он основан на одной идее: если одинаковые символы идут подряд (образуют "серию"), можно записать их как пару (символ, количество повторений).

**Когда RLE эффективен:**

- Изображения с большими однородными областями (например, факсы, чертежи)
- Файлы с повторяющимися символами (например, текст с множеством пробелов)

**Когда RLE неэффективен:**

- Данные без повторений (размер может даже увеличиться!)
- Фотографии, где каждый пиксель разный


#### Алгоритм работы

1. Читаем первый символ
2. Считаем, сколько раз он повторяется подряд
3. Записываем: количество + символ
4. Переходим к следующему символу
5. Повторяем шаги 2-4 до конца данных

#### Пример работы

**Входные данные:** `AAAAAABBBCDDDD`

**Процесс кодирования:**

- A повторяется 6 раз → `6A`
- B повторяется 3 раза → `3B`
- C повторяется 1 раз → `1C`
- D повторяется 4 раза → `4D`

**Результат:** `6A3B1C4D`

Исходный размер: 14 символов
Сжатый размер: 8 символов (с учётом цифр)
Коэффициент сжатия: 14/8 = 1.75 (сжали в 1.75 раза)

#### Реализация на C++

```cpp
#include <iostream>
#include <string>
#include <vector>

using namespace std;

// Структура для хранения закодированного символа
struct RLEElement {
    char symbol;    // Сам символ
    int count;      // Количество повторений
};

// Функция кодирования RLE
vector<RLEElement> rleEncode(const string& input) {
    vector<RLEElement> result;  // Вектор для хранения результата
    
    // Проверка на пустую строку
    if (input.empty()) {
        return result;
    }
    
    int i = 0;  // Индекс текущего символа
    
    // Проходим по всей строке
    while (i < input.length()) {
        char currentChar = input[i];  // Запоминаем текущий символ
        int count = 1;  // Счётчик повторений (минимум 1)
        
        // Считаем, сколько раз символ повторяется подряд
        while (i + count < input.length() && input[i + count] == currentChar) {
            count++;  // Увеличиваем счётчик
        }
        
        // Создаём элемент и добавляем в результат
        RLEElement element;
        element.symbol = currentChar;
        element.count = count;
        result.push_back(element);
        
        // Переходим к следующей группе символов
        i += count;
    }
    
    return result;
}

// Функция декодирования RLE
string rleDecode(const vector<RLEElement>& encoded) {
    string result;  // Строка для результата
    
    // Проходим по всем закодированным элементам
    for (const auto& element : encoded) {
        // Добавляем символ нужное количество раз
        for (int i = 0; i < element.count; i++) {
            result += element.symbol;
        }
    }
    
    return result;
}

// Функция для вывода закодированных данных
void printEncoded(const vector<RLEElement>& encoded) {
    cout << "Закодированные данные: ";
    for (const auto& element : encoded) {
        cout << element.count << element.symbol << " ";
    }
    cout << endl;
}

// Демонстрация работы
int main() {
    // Исходная строка
    string original = "AAAAAABBBCDDDD";
    
    cout << "Исходная строка: " << original << endl;
    cout << "Длина исходной строки: " << original.length() << " символов" << endl;
    
    // Кодируем
    vector<RLEElement> encoded = rleEncode(original);
    printEncoded(encoded);
    
    // Декодируем обратно
    string decoded = rleDecode(encoded);
    cout << "Декодированная строка: " << decoded << endl;
    
    // Проверяем корректность
    if (original == decoded) {
        cout << "✓ Декодирование прошло успешно!" << endl;
    } else {
        cout << "✗ Ошибка декодирования!" << endl;
    }
    
    // Вычисляем коэффициент сжатия (примерный)
    // Предполагаем, что каждый элемент занимает 2 байта (счётчик + символ)
    int compressedSize = encoded.size() * 2;
    cout << "Сжатый размер: ~" << compressedSize << " байт" << endl;
    cout << "Коэффициент сжатия: " << (float)original.length() / compressedSize << endl;
    
    return 0;
}
```


#### Улучшенная версия RLE с обработкой одиночных символов

В реальных реализациях RLE часто используют специальные маркеры, чтобы не увеличивать размер при одиночных символах:

```cpp
// Улучшенная версия RLE для работы с бинарными данными
string rleEncodeBinary(const string& input) {
    string result;
    
    if (input.empty()) return result;
    
    int i = 0;
    
    while (i < input.length()) {
        char currentChar = input[i];
        int count = 1;
        
        // Считаем повторения (максимум 255 для одного байта)
        while (i + count < input.length() && 
               input[i + count] == currentChar && 
               count < 255) {
            count++;
        }
        
        // Если повторений больше 3, используем RLE
        // Иначе записываем символы как есть
        if (count >= 3) {
            result += (char)count;      // Количество (1 байт)
            result += currentChar;       // Символ (1 байт)
        } else {
            // Записываем символы без сжатия
            for (int j = 0; j < count; j++) {
                result += currentChar;
            }
        }
        
        i += count;
    }
    
    return result;
}
```

**Важная деталь:** В этой версии мы сжимаем только последовательности из 3 и более символов. Это предотвращает увеличение размера файла при наличии одиночных или парных символов.

***

### 3.2 Кодирование Шеннона-Фано

#### Теория

Кодирование Шеннона-Фано — это один из первых методов эффективного кодирования, предложенный Клодом Шенноном и Робертом Фано. Этот метод строит префиксный код переменной длины, основываясь на вероятностях символов.

**Основная идея:** Разделяй и властвуй! Мы делим множество символов на две части с примерно равными суммарными вероятностями, присваиваем одной части код "0", другой — "1", и рекурсивно повторяем процесс.

**Свойства кода Шеннона-Фано:**

- Префиксный код (никакой код не является началом другого)
- Длина кода зависит от частоты символа
- Не всегда оптимален (в отличие от кода Хаффмана)


#### Алгоритм построения

1. **Подсчитываем частоты** всех символов в сообщении
2. **Сортируем символы** по убыванию частоты
3. **Разделяем список** на две части с примерно равными суммарными частотами
4. Присваиваем верхней части бит "0", нижней — "1"
5. **Рекурсивно применяем** шаги 3-4 к каждой части
6. Останавливаемся, когда в группе остаётся один символ

#### Пример работы

Рассмотрим строку: `AAAAABBBCCD`

**Шаг 1: Подсчитываем частоты**

- A: 5 раз (частота = 5/11 ≈ 0.45)
- B: 3 раза (частота = 3/11 ≈ 0.27)
- C: 2 раза (частота = 2/11 ≈ 0.18)
- D: 1 раз (частота = 1/11 ≈ 0.09)

**Шаг 2: Сортируем**

```
A: 5
B: 3
C: 2
D: 1
```

**Шаг 3: Начинаем разделение**

```
Итерация 1:
┌─────────────┐
│ A(5) B(3)   │ ← Сумма = 8, присваиваем "0"
│ C(2) D(1)   │ ← Сумма = 3, присваиваем "1"
└─────────────┘

Итерация 2 (для верхней группы):
┌─────────────┐
│ A(5)        │ ← "00"
│ B(3)        │ ← "01"
└─────────────┘

Итерация 3 (для нижней группы):
┌─────────────┐
│ C(2)        │ ← "10"
│ D(1)        │ ← "11"
└─────────────┘
```

**Результат кодирования:**

- A → `00`
- B → `01`
- C → `10`
- D → `11`

**Кодируем исходную строку:**
`AAAAABBBCCD` → `00 00 00 00 00 01 01 01 10 10 11`

Без пробелов: `00000000000101011010011`

Исходный размер: 11 символов × 8 бит = 88 бит (если использовать ASCII)
Сжатый размер: 22 бита
Коэффициент сжатия: 88/22 = 4 раза

#### Реализация на C++

```cpp
#include <iostream>
#include <string>
#include <vector>
#include <map>
#include <algorithm>

using namespace std;

// Структура для хранения символа и его частоты
struct Symbol {
    char character;   // Символ
    int frequency;    // Частота появления
    string code;      // Код Шеннона-Фано
    
    // Конструктор
    Symbol(char c, int f) : character(c), frequency(f), code("") {}
};

// Функция сравнения для сортировки по убыванию частоты
bool compareByFrequency(const Symbol& a, const Symbol& b) {
    return a.frequency > b.frequency;  // Сортируем от большего к меньшему
}

// Рекурсивная функция построения кода Шеннона-Фано
void buildShannonFanoCode(vector<Symbol>& symbols, int start, int end, string prefix) {
    // Базовый случай: один символ в диапазоне
    if (start == end) {
        symbols[start].code = prefix;
        return;
    }
    
    // Базовый случай: два символа в диапазоне
    if (end - start == 1) {
        symbols[start].code = prefix + "0";
        symbols[end].code = prefix + "1";
        return;
    }
    
    // Вычисляем общую сумму частот в диапазоне
    int totalFreq = 0;
    for (int i = start; i <= end; i++) {
        totalFreq += symbols[i].frequency;
    }
    
    // Ищем точку разделения на две примерно равные части
    int sum = 0;
    int splitPoint = start;
    int halfFreq = totalFreq / 2;  // Половина общей частоты
    
    // Идём по символам и накапливаем сумму
    for (int i = start; i <= end; i++) {
        sum += symbols[i].frequency;
        // Находим момент, когда накопленная сумма близка к половине
        if (sum >= halfFreq) {
            splitPoint = i;
            break;
        }
    }
    
    // Рекурсивно строим коды для двух частей
    // Верхняя часть получает префикс "0"
    buildShannonFanoCode(symbols, start, splitPoint, prefix + "0");
    // Нижняя часть получает префикс "1"
    buildShannonFanoCode(symbols, splitPoint + 1, end, prefix + "1");
}

// Главная функция кодирования Шеннона-Фано
map<char, string> shannonFanoEncode(const string& input) {
    // Шаг 1: Подсчитываем частоты символов
    map<char, int> frequencies;
    for (char c : input) {
        frequencies[c]++;  // Увеличиваем счётчик для символа
    }
    
    // Шаг 2: Создаём вектор символов с частотами
    vector<Symbol> symbols;
    for (const auto& pair : frequencies) {
        symbols.push_back(Symbol(pair.first, pair.second));
    }
    
    // Шаг 3: Сортируем по убыванию частоты
    sort(symbols.begin(), symbols.end(), compareByFrequency);
    
    // Вывод частот для демонстрации
    cout << "\nЧастоты символов (отсортированные):" << endl;
    for (const auto& sym : symbols) {
        cout << "'" << sym.character << "': " << sym.frequency << " раз" << endl;
    }
    
    // Шаг 4: Строим коды Шеннона-Фано
    buildShannonFanoCode(symbols, 0, symbols.size() - 1, "");
    
    // Шаг 5: Создаём словарь кодов
    map<char, string> codeTable;
    cout << "\nТаблица кодов Шеннона-Фано:" << endl;
    for (const auto& sym : symbols) {
        codeTable[sym.character] = sym.code;
        cout << "'" << sym.character << "' → " << sym.code << endl;
    }
    
    return codeTable;
}

// Функция кодирования строки
string encodeString(const string& input, const map<char, string>& codeTable) {
    string encoded;
    // Заменяем каждый символ его кодом
    for (char c : input) {
        encoded += codeTable.at(c);
    }
    return encoded;
}

// Функция декодирования строки
string decodeString(const string& encoded, const map<char, string>& codeTable) {
    string decoded;
    string buffer;  // Буфер для накопления битов
    
    // Создаём обратный словарь (код → символ)
    map<string, char> reverseTable;
    for (const auto& pair : codeTable) {
        reverseTable[pair.second] = pair.first;
    }
    
    // Читаем биты по одному
    for (char bit : encoded) {
        buffer += bit;  // Добавляем бит в буфер
        
        // Проверяем, есть ли такой код в таблице
        if (reverseTable.find(buffer) != reverseTable.end()) {
            decoded += reverseTable[buffer];  // Добавляем декодированный символ
            buffer.clear();  // Очищаем буфер
        }
    }
    
    return decoded;
}

// Демонстрация работы
int main() {
    string original = "AAAAABBBCCD";
    
    cout << "Исходная строка: " << original << endl;
    cout << "Длина: " << original.length() << " символов" << endl;
    
    // Строим таблицу кодов
    map<char, string> codeTable = shannonFanoEncode(original);
    
    // Кодируем строку
    string encoded = encodeString(original, codeTable);
    cout << "\nЗакодированная строка:" << endl;
    cout << encoded << endl;
    cout << "Длина: " << encoded.length() << " бит" << endl;
    
    // Декодируем обратно
    string decoded = decodeString(encoded, codeTable);
    cout << "\nДекодированная строка: " << decoded << endl;
    
    // Проверяем корректность
    if (original == decoded) {
        cout << "✓ Декодирование прошло успешно!" << endl;
    } else {
        cout << "✗ Ошибка декодирования!" << endl;
    }
    
    // Вычисляем коэффициент сжатия
    int originalSize = original.length() * 8;  // ASCII: 8 бит на символ
    int compressedSize = encoded.length();      // Биты закодированной строки
    cout << "\nСтатистика сжатия:" << endl;
    cout << "Исходный размер: " << originalSize << " бит" << endl;
    cout << "Сжатый размер: " << compressedSize << " бит" << endl;
    cout << "Коэффициент сжатия: " << (float)originalSize / compressedSize << endl;
    cout << "Экономия: " << 100 - (compressedSize * 100 / originalSize) << "%" << endl;
    
    return 0;
}
```

**Важные замечания:**

1. **Префиксность кода:** Никакой код не является началом другого кода. Это позволяет декодировать без разделителей.
2. **Оптимальность:** Код Шеннона-Фано не всегда даёт оптимальное сжатие. Например, для строки "AAAB" он может дать коды: A→0, B→1 (средняя длина 1 бит), но можно было бы использовать A→1, B→0 с тем же результатом.
3. **Сложность:** Алгоритм имеет сложность O(n log n) из-за сортировки, где n — количество уникальных символов.

***

### 3.3 Кодирование Хаффмана

#### Теория

Кодирование Хаффмана — это улучшенная версия кодирования Шеннона-Фано, которая **гарантирует оптимальность**. Алгоритм был разработан Дэвидом Хаффманом в 1952 году и до сих пор широко используется (в JPEG, MP3, ZIP и многих других форматах).

**Ключевое отличие от Шеннона-Фано:** Вместо того чтобы делить множество символов на части, мы строим дерево **снизу вверх**, объединяя самые редкие символы в группы.

**Свойства кода Хаффмана:**

- Префиксный код (как и Шеннона-Фано)
- **Оптимальный** — даёт минимально возможную среднюю длину кода
- Более частые символы всегда имеют более короткие коды
- Средняя длина кода близка к энтропии источника


#### Алгоритм построения дерева Хаффмана

1. **Создаём листья** — для каждого символа создаём узел с его частотой
2. **Помещаем** все узлы в приоритетную очередь (сортировка по частоте)
3. **Пока в очереди больше одного узла:**
    - Извлекаем два узла с минимальной частотой
    - Создаём новый внутренний узел с суммарной частотой
    - Делаем извлечённые узлы детьми нового узла
    - Помещаем новый узел обратно в очередь
4. **Оставшийся узел** — корень дерева
5. **Строим коды:** проходим от корня к листьям, налево = 0, направо = 1

#### Визуальный пример

Для строки `AAAAABBBCCD`:

**Шаг 1: Частоты**

```
A: 5
B: 3
C: 2
D: 1
```

**Шаг 2-4: Построение дерева**

```
Итерация 1: Объединяем D(1) и C(2)
    (3)
   /   \
  D(1) C(2)

Очередь: A(5), B(3), (3)

Итерация 2: Объединяем (3) и B(3)
      (6)
     /   \
   (3)   B(3)
  /   \
 D(1) C(2)

Очередь: A(5), (6)

Итерация 3: Объединяем A(5) и (6)
        (11)
       /    \
     A(5)   (6)
           /   \
         (3)   B(3)
        /   \
       D(1) C(2)
```

**Шаг 5: Присваиваем коды**

Проходим от корня к каждому листу:

- A: влево от корня → `0`
- B: вправо, вправо → `11`
- C: вправо, влево, вправо → `101`
- D: вправо, влево, влево → `100`

**Таблица кодов:**

- A → `0` (самый частый → самый короткий)
- B → `11`
- C → `101`
- D → `100`

**Кодируем строку:**
`AAAAABBBCCD` → `0 0 0 0 0 11 11 11 101 101 100`
Без пробелов: `00000111111101101100` (20 бит)

Исходный размер: 11 символов × 8 бит = 88 бит
Сжатый размер: 20 бит
Коэффициент сжатия: 88/20 = 4.4 раза

#### Реализация на C++

```cpp
#include <iostream>
#include <string>
#include <map>
#include <queue>
#include <vector>

using namespace std;

// Узел дерева Хаффмана
struct HuffmanNode {
    char character;           // Символ (для листьев)
    int frequency;            // Частота (вес узла)
    HuffmanNode* left;        // Левый потомок
    HuffmanNode* right;       // Правый потомок
    
    // Конструктор для листа (символ)
    HuffmanNode(char c, int f) : character(c), frequency(f), left(nullptr), right(nullptr) {}
    
    // Конструктор для внутреннего узла
    HuffmanNode(int f, HuffmanNode* l, HuffmanNode* r) 
        : character('\0'), frequency(f), left(l), right(r) {}
    
    // Проверка, является ли узел листом
    bool isLeaf() const {
        return (left == nullptr && right == nullptr);
    }
};

// Компаратор для приоритетной очереди (минимальная куча)
struct CompareNodes {
    bool operator()(HuffmanNode* a, HuffmanNode* b) {
        // Возвращаем true, если a имеет БОЛЬШУЮ частоту (для минимальной кучи)
        return a->frequency > b->frequency;
    }
};

// Функция построения дерева Хаффмана
HuffmanNode* buildHuffmanTree(const map<char, int>& frequencies) {
    // Создаём приоритетную очередь (минимальная куча)
    priority_queue<HuffmanNode*, vector<HuffmanNode*>, CompareNodes> pq;
    
    // Создаём листья для каждого символа и помещаем в очередь
    for (const auto& pair : frequencies) {
        HuffmanNode* leaf = new HuffmanNode(pair.first, pair.second);
        pq.push(leaf);
    }
    
    // Строим дерево снизу вверх
    while (pq.size() > 1) {
        // Извлекаем два узла с минимальной частотой
        HuffmanNode* left = pq.top();
        pq.pop();
        HuffmanNode* right = pq.top();
        pq.pop();
        
        // Создаём новый внутренний узел
        int sumFreq = left->frequency + right->frequency;
        HuffmanNode* parent = new HuffmanNode(sumFreq, left, right);
        
        // Помещаем новый узел обратно в очередь
        pq.push(parent);
        
        // Выводим информацию о слиянии для демонстрации
        cout << "Объединяем узлы с частотами " << left->frequency 
             << " и " << right->frequency 
             << " → новый узел с частотой " << sumFreq << endl;
    }
    
    // Возвращаем корень дерева
    return pq.top();
}

// Рекурсивная функция построения кодов
void buildCodes(HuffmanNode* root, string code, map<char, string>& codeTable) {
    // Базовый случай: пустой узел
    if (root == nullptr) return;
    
    // Если это лист, сохраняем код для символа
    if (root->isLeaf()) {
        codeTable[root->character] = code.empty() ? "0" : code;  // Особый случай для одного символа
        return;
    }
    
    // Рекурсивно обходим дерево
    buildCodes(root->left, code + "0", codeTable);   // Налево = 0
    buildCodes(root->right, code + "1", codeTable);  // Направо = 1
}

// Главная функция кодирования Хаффмана
map<char, string> huffmanEncode(const string& input, HuffmanNode*& root) {
    // Шаг 1: Подсчитываем частоты символов
    map<char, int> frequencies;
    for (char c : input) {
        frequencies[c]++;
    }
    
    cout << "\nЧастоты символов:" << endl;
    for (const auto& pair : frequencies) {
        cout << "'" << pair.first << "': " << pair.second << " раз" << endl;
    }
    
    // Шаг 2: Строим дерево Хаффмана
    cout << "\nПостроение дерева Хаффмана:" << endl;
    root = buildHuffmanTree(frequencies);
    
    // Шаг 3: Строим таблицу кодов
    map<char, string> codeTable;
    buildCodes(root, "", codeTable);
    
    cout << "\nТаблица кодов Хаффмана:" << endl;
    for (const auto& pair : codeTable) {
        cout << "'" << pair.first << "' → " << pair.second << endl;
    }
    
    return codeTable;
}

// Функция кодирования строки
string encodeString(const string& input, const map<char, string>& codeTable) {
    string encoded;
    for (char c : input) {
        encoded += codeTable.at(c);
    }
    return encoded;
}

// Функция декодирования с использованием дерева
string decodeString(const string& encoded, HuffmanNode* root) {
    string decoded;
    HuffmanNode* current = root;  // Начинаем с корня
    
    // Особый случай: одно дерево из одного узла
    if (root->isLeaf()) {
        for (int i = 0; i < encoded.length(); i++) {
            decoded += root->character;
        }
        return decoded;
    }
    
    // Проходим по битам закодированной строки
    for (char bit : encoded) {
        // Идём по дереву в зависимости от бита
        if (bit == '0') {
            current = current->left;
        } else {
            current = current->right;
        }
        
        // Если достигли листа, добавляем символ и возвращаемся к корню
        if (current->isLeaf()) {
            decoded += current->character;
            current = root;  // Возвращаемся к корню для следующего символа
        }
    }
    
    return decoded;
}

// Функция освобождения памяти дерева
void deleteTree(HuffmanNode* root) {
    if (root == nullptr) return;
    deleteTree(root->left);
    deleteTree(root->right);
    delete root;
}

// Функция вычисления средней длины кода
double calculateAverageLength(const string& input, const map<char, string>& codeTable) {
    map<char, int> frequencies;
    for (char c : input) {
        frequencies[c]++;
    }
    
    double totalBits = 0;
    int totalChars = input.length();
    
    for (const auto& pair : frequencies) {
        char symbol = pair.first;
        int freq = pair.second;
        int codeLength = codeTable.at(symbol).length();
        totalBits += freq * codeLength;
    }
    
    return totalBits / totalChars;
}

// Демонстрация работы
int main() {
    string original = "AAAAABBBCCD";
    
    cout << "Исходная строка: " << original << endl;
    cout << "Длина: " << original.length() << " символов" << endl;
    
    // Строим дерево и таблицу кодов
    HuffmanNode* root = nullptr;
    map<char, string> codeTable = huffmanEncode(original, root);
    
    // Кодируем строку
    string encoded = encodeString(original, codeTable);
    cout << "\nЗакодированная строка:" << endl;
    cout << encoded << endl;
    cout << "Длина: " << encoded.length() << " бит" << endl;
    
    // Декодируем обратно
    string decoded = decodeString(encoded, root);
    cout << "\nДекодированная строка: " << decoded << endl;
    
    // Проверяем корректность
    if (original == decoded) {
        cout << "✓ Декодирование прошло успешно!" << endl;
    } else {
        cout << "✗ Ошибка декодирования!" << endl;
    }
    
    // Статистика
    int originalSize = original.length() * 8;
    int compressedSize = encoded.length();
    double avgLength = calculateAverageLength(original, codeTable);
    
    cout << "\nСтатистика сжатия:" << endl;
    cout << "Исходный размер: " << originalSize << " бит" << endl;
    cout << "Сжатый размер: " << compressedSize << " бит" << endl;
    cout << "Средняя длина кода: " << avgLength << " бит/символ" << endl;
    cout << "Коэффициент сжатия: " << (float)originalSize / compressedSize << endl;
    cout << "Экономия: " << 100 - (compressedSize * 100 / originalSize) << "%" << endl;
    
    // Освобождаем память
    deleteTree(root);
    
    return 0;
}
```


#### Важные детали реализации

**1. Приоритетная очередь (минимальная куча)**

Мы используем `priority_queue` с пользовательским компаратором. Это позволяет эффективно извлекать узлы с минимальной частотой за O(log n).

**2. Префиксность кода**

Благодаря структуре дерева, никакой код не может быть префиксом другого. Это достигается тем, что символы находятся только в листьях дерева.

**3. Декодирование**

Для декодирования мы идём по дереву, используя биты закодированной строки как инструкции: 0 = налево, 1 = направо. Когда достигаем листа, выводим символ и возвращаемся к корню.

**4. Особый случай**

Если в строке только один уникальный символ, дерево состоит из одного узла. В этом случае мы присваиваем ему код "0".

#### Сравнение с кодом Шеннона-Фано

Для той же строки `AAAAABBBCCD`:

**Шеннон-Фано:**

- A → 00 (2 бита)
- B → 01 (2 бита)
- C → 10 (2 бита)
- D → 11 (2 бита)
- Итого: 11 символов × 2 бита = 22 бита

**Хаффман:**

- A → 0 (1 бит)
- B → 11 (2 бита)
- C → 101 (3 бита)
- D → 100 (3 бита)
- Итого: 5×1 + 3×2 + 2×3 + 1×3 = 5 + 6 + 6 + 3 = 20 бит

**Хаффман даёт на 2 бита меньше — это и есть оптимальность!**

***

### 3.4 Арифметическое кодирование

#### Теория

Арифметическое кодирование — это один из самых эффективных методов сжатия, который может достичь эффективности, **практически равной энтропии источника**. В отличие от кода Хаффмана, который присваивает каждому символу целое число бит, арифметическое кодирование представляет **всё сообщение одним вещественным числом** в интервале $[0, 1)$.

**Основная идея:** Каждый символ "сужает" текущий интервал пропорционально своей вероятности. В конце кодирования мы получаем маленький интервал, и любое число из этого интервала однозначно представляет исходное сообщение.

**Почему это эффективно?**

Представьте, что у нас есть сообщение из очень частого символа A (вероятность 0.99) и редкого B (вероятность 0.01). Код Хаффмана всё равно выделит каждому символу минимум 1 бит. Но арифметическое кодирование может закодировать несколько символов A меньше чем одним битом в среднем!

#### Алгоритм кодирования

**Начальные условия:**

- Текущий интервал: $[0, 1)$
- Вероятности символов известны

**Для каждого символа в сообщении:**

1. Вычисляем ширину текущего интервала: `width = high - low`
2. Делим интервал на части пропорционально вероятностям символов
3. Выбираем часть, соответствующую текущему символу
4. Обновляем границы интервала

**После обработки всех символов:**

- Выбираем любое число из финального интервала
- Это число и есть закодированное сообщение


#### Пример работы

Закодируем сообщение `"CAB"` с вероятностями:

- A: 0.5 (50%)
- B: 0.3 (30%)
- C: 0.2 (20%)

**Начальное состояние:**

```
Интервал: [0, 1)
Разбиение на части:
C: [0.0, 0.2)
A: [0.2, 0.7)
B: [0.7, 1.0)
```

**Шаг 1: Кодируем 'C'**

```
Текущий интервал: [0, 1)
Выбираем часть для C: [0.0, 0.2)
Новый интервал: [0.0, 0.2)
```

**Шаг 2: Кодируем 'A'**

```
Текущий интервал: [0.0, 0.2)
Ширина = 0.2 - 0.0 = 0.2
Делим интервал:
  C: [0.0, 0.0 + 0.2×0.2) = [0.0, 0.04)
  A: [0.04, 0.04 + 0.2×0.5) = [0.04, 0.14)
  B: [0.14, 0.14 + 0.2×0.3) = [0.14, 0.2)
Выбираем часть для A: [0.04, 0.14)
Новый интервал: [0.04, 0.14)
```

**Шаг 3: Кодируем 'B'**

```
Текущий интервал: [0.04, 0.14)
Ширина = 0.14 - 0.04 = 0.1
Делим интервал:
  C: [0.04, 0.04 + 0.1×0.2) = [0.04, 0.06)
  A: [0.06, 0.06 + 0.1×0.5) = [0.06, 0.11)
  B: [0.11, 0.11 + 0.1×0.3) = [0.11, 0.14)
Выбираем часть для B: [0.11, 0.14)
Новый интервал: [0.11, 0.14)
```

**Результат:** Финальный интервал `[0.11, 0.14)`. Любое число из этого интервала кодирует сообщение "CAB". Например, можно выбрать 0.12 или 0.13.

#### Декодирование

Для декодирования мы повторяем процесс:

1. Берём закодированное число (например, 0.12)
2. Смотрим, в какой части интервала $[0, 1)$ оно находится
3. Это определяет первый символ (0.12 попадает в [0.0, 0.2) → это 'C')
4. Повторяем процесс для следующего символа, используя обновлённый интервал

#### Реализация на C++

```cpp
#include <iostream>
#include <string>
#include <map>
#include <vector>
#include <iomanip>

using namespace std;

// Структура для хранения интервала символа
struct SymbolRange {
    double low;   // Нижняя граница
    double high;  // Верхняя граница
};

// Класс для арифметического кодирования
class ArithmeticCoder {
private:
    map<char, double> probabilities;  // Вероятности символов
    map<char, SymbolRange> ranges;    // Интервалы символов
    
    // Функция построения интервалов из вероятностей
    void buildRanges() {
        double cumulative = 0.0;  // Накопленная вероятность
        
        // Для каждого символа создаём интервал
        for (const auto& pair : probabilities) {
            char symbol = pair.first;
            double prob = pair.second;
            
            // Интервал начинается с накопленной вероятности
            ranges[symbol].low = cumulative;
            // И заканчивается после добавления вероятности символа
            ranges[symbol].high = cumulative + prob;
            
            cumulative += prob;  // Обновляем накопленную вероятность
        }
    }
    
public:
    // Конструктор: принимает вероятности символов
    ArithmeticCoder(const map<char, double>& probs) : probabilities(probs) {
        buildRanges();
    }
    
    // Функция кодирования
    double encode(const string& message) {
        double low = 0.0;    // Нижняя граница текущего интервала
        double high = 1.0;   // Верхняя граница текущего интервала
        
        cout << "\nПроцесс кодирования:" << endl;
        cout << fixed << setprecision(6);
        cout << "Начальный интервал: [" << low << ", " << high << ")" << endl;
        
        // Обрабатываем каждый символ сообщения
        for (char symbol : message) {
            // Проверяем, что символ существует
            if (ranges.find(symbol) == ranges.end()) {
                cerr << "Ошибка: неизвестный символ '" << symbol << "'" << endl;
                return -1;
            }
            
            // Вычисляем ширину текущего интервала
            double width = high - low;
            
            // Получаем интервал символа
            double symbolLow = ranges[symbol].low;
            double symbolHigh = ranges[symbol].high;
            
            // Обновляем границы интервала
            high = low + width * symbolHigh;
            low = low + width * symbolLow;
            
            cout << "После символа '" << symbol << "': [" << low << ", " << high << ")" << endl;
        }
        
        // Возвращаем среднее значение финального интервала
        double result = (low + high) / 2.0;
        cout << "Финальное число: " << result << endl;
        return result;
    }
    
    // Функция декодирования
    string decode(double code, int messageLength) {
        string decoded;
        
        cout << "\nПроцесс декодирования:" << endl;
        cout << "Код: " << code << endl;
        cout << "Ожидаемая длина: " << messageLength << " символов" << endl;
        
        // Декодируем указанное количество символов
        for (int i = 0; i < messageLength; i++) {
            double low = 0.0;
            double high = 1.0;
            
            // Ищем символ, в чей интервал попадает код
            for (const auto& pair : ranges) {
                char symbol = pair.first;
                double symbolLow = pair.second.low;
                double symbolHigh = pair.second.high;
                
                // Вычисляем границы интервала для этого символа
                double intervalLow = low + (high - low) * symbolLow;
                double intervalHigh = low + (high - low) * symbolHigh;
                
                // Проверяем, попадает ли код в этот интервал
                if (code >= intervalLow && code < intervalHigh) {
                    decoded += symbol;
                    cout << "Символ " << (i + 1) << ": '" << symbol << "'" << endl;
                    
                    // Обновляем границы для следующей итерации
                    low = intervalLow;
                    high = intervalHigh;
                    break;
                }
            }
        }
        
        return decoded;
    }
    
    // Функция вывода таблицы интервалов
    void printRanges() {
        cout << "\nТаблица интервалов символов:" << endl;
        cout << fixed << setprecision(6);
        for (const auto& pair : ranges) {
            cout << "'" << pair.first << "': [" 
                 << pair.second.low << ", " << pair.second.high << ")" 
                 << " (вероятность: " << probabilities[pair.first] << ")" << endl;
        }
    }
};

// Функция подсчёта вероятностей из строки
map<char, double> calculateProbabilities(const string& text) {
    map<char, int> frequencies;
    
    // Подсчитываем частоты
    for (char c : text) {
        frequencies[c]++;
    }
    
    // Вычисляем вероятности
    map<char, double> probabilities;
    int totalChars = text.length();
    
    for (const auto& pair : frequencies) {
        probabilities[pair.first] = (double)pair.second / totalChars;
    }
    
    return probabilities;
}

// Демонстрация работы
int main() {
    // Исходное сообщение
    string message = "CAB";
    
    cout << "Исходное сообщение: " << message << endl;
    cout << "Длина: " << message.length() << " символов" << endl;
    
    // Вычисляем вероятности на основе сообщения
    // (В реальности вероятности могут быть известны заранее)
    map<char, double> probabilities;
    probabilities['A'] = 0.5;
    probabilities['B'] = 0.3;
    probabilities['C'] = 0.2;
    
    cout << "\nВероятности символов:" << endl;
    for (const auto& pair : probabilities) {
        cout << "'" << pair.first << "': " << pair.second << endl;
    }
    
    // Создаём кодер
    ArithmeticCoder coder(probabilities);
    coder.printRanges();
    
    // Кодируем сообщение
    double encoded = coder.encode(message);
    
    // Декодируем обратно
    string decoded = coder.decode(encoded, message.length());
    
    cout << "\nДекодированное сообщение: " << decoded << endl;
    
    // Проверяем корректность
    if (message == decoded) {
        cout << "✓ Декодирование прошло успешно!" << endl;
    } else {
        cout << "✗ Ошибка декодирования!" << endl;
    }
    
    // Оценка эффективности
    cout << "\nСтатистика:" << endl;
    cout << "Исходный размер: " << message.length() * 8 << " бит (ASCII)" << endl;
    
    // Для двоичного представления числа нужно log2(1/ширина_интервала) бит
    // Это приблизительная оценка
    cout << "Арифметическое кодирование позволяет достичь эффективности," << endl;
    cout << "близкой к энтропии источника." << endl;
    
    return 0;
}
```


#### Практическая реализация: учёт точности

В реальной реализации арифметического кодирования есть важная проблема: по мере кодирования длинных сообщений интервал становится очень узким, и возникают проблемы с точностью вычислений. Для решения этой проблемы используется техника **масштабирования**:

```cpp
// Упрощённая версия с масштабированием
class PracticalArithmeticCoder {
private:
    const int PRECISION = 16;  // Количество бит точности
    const int MAX_VALUE = (1 << PRECISION) - 1;  // Максимальное значение
    const int HALF = MAX_VALUE / 2 + 1;
    const int QUARTER = HALF / 2;
    
    int low;   // Нижняя граница (целое число)
    int high;  // Верхняя граница (целое число)
    
public:
    PracticalArithmeticCoder() : low(0), high(MAX_VALUE) {}
    
    // Функция масштабирования при кодировании
    void rescale(vector<int>& output) {
        // Пока старшие биты low и high одинаковы
        while ((low >> (PRECISION - 1)) == (high >> (PRECISION - 1))) {
            // Выводим старший бит
            int bit = low >> (PRECISION - 1);
            output.push_back(bit);
            
            // Сдвигаем границы влево
            low = (low << 1) & MAX_VALUE;
            high = ((high << 1) & MAX_VALUE) | 1;
        }
        
        // Обработка случая, когда low и high близки к HALF
        while ((low >= QUARTER) && (high < HALF + QUARTER)) {
            // Инвертируем второй старший бит
            low = (low << 1) & MAX_VALUE;
            high = ((high << 1) & MAX_VALUE) | 1;
        }
    }
};
```

Эта техника позволяет кодировать сообщения любой длины без потери точности.

#### Преимущества и недостатки

**Преимущества:**

- Достигает эффективности, близкой к энтропии
- Может кодировать дробные биты на символ
- Адаптивные версии не требуют передачи таблицы вероятностей

**Недостатки:**

- Сложнее в реализации, чем Хаффман
- Требует аккуратной работы с точностью
- Последовательное кодирование (нельзя начать с середины)

***

### 3.5 Словарные методы: LZ77, LZ78, LZW

#### Теория

Все предыдущие методы (Хаффман, Шеннон-Фано, арифметическое) основаны на **статистике символов**. Словарные методы работают по-другому: они ищут **повторяющиеся последовательности** и заменяют их ссылками.

**Основная идея:** Если фраза уже встречалась в тексте, зачем писать её снова? Можно просто сказать: "то же самое, что было 100 символов назад, длиной 15 символов".

**Пример на русском языке:**

Исходный текст:

```
Иванов Иван Иванович пошёл к Иванову Ивану Ивановичу.
```

Со словарным сжатием:

```
Иванов Иван Иванович пошёл к [ссылка: -29, длина: 27].
```

Мы не повторяем "Иванову Ивану Ивановичу", а ссылаемся на "Иванов Иван Иванович", который уже был написан ранее.

#### Алгоритм LZ77 (Лемпель-Зив 1977)

**Принцип работы:**

LZ77 использует **скользящее окно**, разделённое на две части:

1. **Буфер поиска (словарь)** — уже обработанные символы (например, последние 4096 байт)
2. **Буфер предпросмотра** — символы, которые будем кодировать сейчас (например, следующие 18 байт)

**Алгоритм:**

1. Ищем в буфере поиска самую длинную последовательность, совпадающую с началом буфера предпросмотра
2. Выводим тройку: (смещение, длина, следующий_символ)
3. Сдвигаем окно вперёд на (длина + 1)

**Пример работы:**

Кодируем строку: `ABCABCABCABC`

```
Позиция 0:
Буфер поиска: [пусто]
Буфер предпросмотра: ABCABCABCABC
Совпадений нет.
Вывод: (0, 0, 'A')

Позиция 1:
Буфер поиска: A
Буфер предпросмотра: BCABCABCABC
Совпадений нет.
Вывод: (0, 0, 'B')

Позиция 2:
Буфер поиска: AB
Буфер предпросмотра: CABCABCABC
Совпадений нет.
Вывод: (0, 0, 'C')

Позиция 3:
Буфер поиска: ABC
Буфер предпросмотра: ABCABCABC
Найдено совпадение! "ABC" на смещении 3 назад, длина 3.
Следующий символ после совпадения: 'A'
Вывод: (3, 3, 'A')

Позиция 7:
Буфер поиска: ABCABCA
Буфер предпросмотра: BCABC
Найдено "BCA" на смещении 4 назад, длина 3.
Или даже лучше: "BCABC" на смещении 4, длина 5!
Вывод: (4, 5, '\0')
```

**Результат:** `(0,0,'A')(0,0,'B')(0,0,'C')(3,3,'A')(4,5,'\0')`

#### Реализация LZ77 на C++

```cpp
#include <iostream>
#include <string>
#include <vector>

using namespace std;

// Структура для хранения триплета LZ77
struct LZ77Token {
    int offset;      // Смещение назад
    int length;      // Длина совпадения
    char nextChar;   // Следующий символ
    
    LZ77Token(int o, int l, char c) : offset(o), length(l), nextChar(c) {}
};

// Класс для LZ77 кодирования
class LZ77Encoder {
private:
    int windowSize;      // Размер окна поиска
    int lookaheadSize;   // Размер буфера предпросмотра
    
    // Функция поиска самой длинной совпадающей последовательности
    pair<int, int> findLongestMatch(const string& data, int currentPos) {
        int bestOffset = 0;    // Лучшее смещение
        int bestLength = 0;    // Лучшая длина
        
        // Определяем начало окна поиска
        int windowStart = max(0, currentPos - windowSize);
        
        // Ищем совпадения в окне поиска
        for (int i = windowStart; i < currentPos; i++) {
            int length = 0;  // Длина текущего совпадения
            
            // Считаем, сколько символов совпадает
            while (length < lookaheadSize &&
                   currentPos + length < data.length() &&
                   data[i + length] == data[currentPos + length]) {
                length++;
            }
            
            // Обновляем лучшее совпадение
            if (length > bestLength) {
                bestOffset = currentPos - i;  // Смещение = расстояние назад
                bestLength = length;
            }
        }
        
        return {bestOffset, bestLength};
    }
    
public:
    // Конструктор
    LZ77Encoder(int wSize = 4096, int lSize = 18) 
        : windowSize(wSize), lookaheadSize(lSize) {}
    
    // Функция кодирования
    vector<LZ77Token> encode(const string& data) {
        vector<LZ77Token> tokens;  // Результат
        int pos = 0;  // Текущая позиция
        
        cout << "\nПроцесс LZ77 кодирования:" << endl;
        
        while (pos < data.length()) {
            // Ищем самое длинное совпадение
            auto [offset, length] = findLongestMatch(data, pos);
            
            // Определяем следующий символ
            char nextChar = '\0';
            if (pos + length < data.length()) {
                nextChar = data[pos + length];
            }
            
            // Создаём токен
            tokens.push_back(LZ77Token(offset, length, nextChar));
            
            // Выводим информацию
            cout << "Позиция " << pos << ": ";
            if (length > 0) {
                cout << "Найдено совпадение: смещение=" << offset 
                     << ", длина=" << length;
            } else {
                cout << "Совпадений нет";
            }
            cout << ", следующий символ='" << nextChar << "'" << endl;
            
            // Сдвигаем позицию
            pos += length + 1;  // Перепрыгиваем совпадение + 1 новый символ
        }
        
        return tokens;
    }
    
    // Функция декодирования
    string decode(const vector<LZ77Token>& tokens) {
        string decoded;
        
        cout << "\nПроцесс LZ77 декодирования:" << endl;
        
        for (const auto& token : tokens) {
            cout << "Токен: offset=" << token.offset 
                 << ", length=" << token.length 
                 << ", next='" << token.nextChar << "'" << endl;
            
            // Если есть совпадение, копируем символы
            if (token.length > 0) {
                int startPos = decoded.length() - token.offset;
                
                // Копируем символ за символом (важно для перекрывающихся областей)
                for (int i = 0; i < token.length; i++) {
                    decoded += decoded[startPos + i];
                }
            }
            
            // Добавляем следующий символ
            if (token.nextChar != '\0') {
                decoded += token.nextChar;
            }
        }
        
        return decoded;
    }
    
    // Функция вывода токенов
    void printTokens(const vector<LZ77Token>& tokens) {
        cout << "\nТокены LZ77:" << endl;
        for (size_t i = 0; i < tokens.size(); i++) {
            cout << i << ": (" << tokens[i].offset << ", " 
                 << tokens[i].length << ", '" << tokens[i].nextChar << "')" << endl;
        }
    }
};

// Демонстрация работы
int main() {
    // Исходная строка
    string original = "ABCABCABCABC";
    
    cout << "Исходная строка: " << original << endl;
    cout << "Длина: " << original.length() << " символов" << endl;
    
    // Создаём кодер с небольшим окном для демонстрации
    LZ77Encoder encoder(100, 10);
    
    // Кодируем
    vector<LZ77Token> tokens = encoder.encode(original);
    encoder.printTokens(tokens);
    
    // Декодируем
    string decoded = encoder.decode(tokens);
    
    cout << "\nДекодированная строка: " << decoded << endl;
    
    // Проверяем корректность
    if (original == decoded) {
        cout << "✓ Декодирование прошло успешно!" << endl;
    } else {
        cout << "✗ Ошибка декодирования!" << endl;
    }
    
    // Оценка сжатия
    int originalSize = original.length() * 8;  // 8 бит на символ
    int compressedSize = tokens.size() * (16 + 8 + 8);  // offset(16) + length(8) + char(8)
    
    cout << "\nСтатистика:" << endl;
    cout << "Исходный размер: " << originalSize << " бит" << endl;
    cout << "Сжатый размер: ~" << compressedSize << " бит" << endl;
    cout << "Коэффициент сжатия: " << (float)originalSize / compressedSize << endl;
    
    return 0;
}
```


#### Важные детали LZ77

**1. Перекрывающиеся области**

Интересный момент: совпадение может "заходить" в буфер предпросмотра! Например:

```
Буфер поиска: ABC
Буфер предпросмотра: ABCABCABC
```

Мы можем закодировать весь предпросмотр одним токеном: (3, 9, '\0'), потому что при декодировании мы копируем символ за символом, и новые символы сразу становятся доступными для дальнейшего копирования.

**2. Размеры окон**

Типичные размеры:

- Буфер поиска: 4096-32768 байт (требует 12-15 бит для offset)
- Буфер предпросмотра: 16-256 байт (требует 4-8 бит для length)

**3. Применение**

LZ77 используется в:

- DEFLATE (ZIP, PNG, gzip)
- LZO
- LZ4


#### Алгоритм LZW (Лемпель-Зив-Велч)

LZW — это улучшенная версия LZ78, которая строит словарь фраз динамически.

**Основная идея:** Вместо того чтобы ссылаться на позиции в уже обработанном тексте, мы строим **явный словарь** фраз. Каждой фразе присваивается уникальный номер.

**Алгоритм кодирования:**

1. Инициализируем словарь всеми одиночными символами (например, для ASCII: 0-255)
2. Читаем символы, формируя фразы
3. Для каждой новой фразы:
    - Если фраза есть в словаре, продолжаем её расширять
    - Если фразы нет, выводим код последней известной фразы и добавляем новую фразу в словарь
4. Повторяем, пока не обработаем все данные

**Пример:**

Кодируем: `ABABABA`

**Начальный словарь:**

```
0: 'A'
1: 'B'
```

**Процесс:**

```
Шаг 1:
  Читаем: A
  "A" в словаре → продолжаем
  Читаем: B
  "AB" НЕ в словаре
  Выводим: 0 (код для "A")
  Добавляем в словарь: 2 = "AB"

Шаг 2:
  Текущий символ: B
  Читаем: A
  "BA" НЕ в словаре
  Выводим: 1 (код для "B")
  Добавляем в словарь: 3 = "BA"

Шаг 3:
  Текущий символ: A
  Читаем: B
  "AB" В СЛОВАРЕ (код 2) → продолжаем
  Читаем: A
  "ABA" НЕ в словаре
  Выводим: 2 (код для "AB")
  Добавляем в словарь: 4 = "ABA"

Шаг 4:
  Текущий символ: A
  Читаем: B
  "AB" в словаре (код 2) → продолжаем
  Читаем: A
  "ABA" В СЛОВАРЕ (код 4) → продолжаем
  Конец данных
  Выводим: 4 (код для "ABA")
```

**Результат:** `0, 1, 2, 4`

Вместо 7 символов мы передали 4 кода!

#### Реализация LZW на C++

```cpp
#include <iostream>
#include <string>
#include <map>
#include <vector>

using namespace std;

// Класс для LZW кодирования
class LZWEncoder {
private:
    int dictionarySize;  // Текущий размер словаря
    
public:
    // Функция кодирования
    vector<int> encode(const string& data) {
        // Инициализируем словарь одиночными символами
        map<string, int> dictionary;
        for (int i = 0; i < 256; i++) {
            string s(1, char(i));  // Создаём строку из одного символа
            dictionary[s] = i;
        }
        dictionarySize = 256;
        
        vector<int> result;  // Закодированные данные
        string current;      // Текущая фраза
        
        cout << "\nПроцесс LZW кодирования:" << endl;
        cout << "Начальный размер словаря: " << dictionarySize << endl;
        
        // Обрабатываем каждый символ
        for (char c : data) {
            string extended = current + c;  // Расширяем текущую фразу
            
            // Проверяем, есть ли расширенная фраза в словаре
            if (dictionary.find(extended) != dictionary.end()) {
                // Фраза есть → продолжаем расширять
                current = extended;
            } else {
                // Фразы нет → выводим код текущей фразы
                int code = dictionary[current];
                result.push_back(code);
                
                cout << "Вывод: " << code << " ('" << current << "')" << endl;
                cout << "Добавляем в словарь: " << dictionarySize 
                     << " = '" << extended << "'" << endl;
                
                // Добавляем новую фразу в словарь
                dictionary[extended] = dictionarySize++;
                
                // Начинаем новую фразу с текущего символа
                current = string(1, c);
            }
        }
        
        // Не забываем вывести последнюю фразу
        if (!current.empty()) {
            int code = dictionary[current];
            result.push_back(code);
            cout << "Вывод: " << code << " ('" << current << "')" << endl;
        }
        
        cout << "Финальный размер словаря: " << dictionarySize << endl;
        
        return result;
    }
    
    // Функция декодирования
    string decode(const vector<int>& encoded) {
        // Инициализируем словарь одиночными символами
        map<int, string> dictionary;
        for (int i = 0; i < 256; i++) {
            dictionary[i] = string(1, char(i));
        }
        dictionarySize = 256;
        
        string result;       // Декодированные данные
        string previous;     // Предыдущая фраза
        
        cout << "\nПроцесс LZW декодирования:" << endl;
        
        // Обрабатываем каждый код
        for (int code : encoded) {
            string current;
            
            // Проверяем, есть ли код в словаре
            if (dictionary.find(code) != dictionary.end()) {
                // Код есть → берём фразу из словаря
                current = dictionary[code];
            } else if (code == dictionarySize) {
                // Особый случай: код ещё не добавлен, но мы его декодируем
                // Это значит, что новая фраза = previous + first_char_of_previous
                current = previous + previous[^0];
            } else {
                cerr << "Ошибка: неверный код " << code << endl;
                return "";
            }
            
            result += current;
            cout << "Код " << code << " → '" << current << "'" << endl;
            
            // Добавляем в словарь новую фразу
            if (!previous.empty()) {
                string newPhrase = previous + current[^0];
                dictionary[dictionarySize] = newPhrase;
                cout << "Добавляем в словарь: " << dictionarySize 
                     << " = '" << newPhrase << "'" << endl;
                dictionarySize++;
            }
            
            previous = current;
        }
        
        return result;
    }
    
    // Функция вывода закодированных данных
    void printEncoded(const vector<int>& encoded) {
        cout << "\nЗакодированные данные: ";
        for (int code : encoded) {
            cout << code << " ";
        }
        cout << endl;
    }
};

// Демонстрация работы
int main() {
    // Исходная строка
    string original = "ABABABA";
    
    cout << "Исходная строка: " << original << endl;
    cout << "Длина: " << original.length() << " символов" << endl;
    
    // Создаём кодер
    LZWEncoder encoder;
    
    // Кодируем
    vector<int> encoded = encoder.encode(original);
    encoder.printEncoded(encoded);
    
    // Декодируем
    string decoded = encoder.decode(encoded);
    
    cout << "\nДекодированная строка: " << decoded << endl;
    
    // Проверяем корректность
    if (original == decoded) {
        cout << "✓ Декодирование прошло успешно!" << endl;
    } else {
        cout << "✗ Ошибка декодирования!" << endl;
    }
    
    // Оценка сжатия
    int originalSize = original.length() * 8;  // 8 бит на символ
    // Предполагаем 12 бит на код (типичное значение)
    int compressedSize = encoded.size() * 12;
    
    cout << "\nСтатистика:" << endl;
    cout << "Исходный размер: " << originalSize << " бит" << endl;
    cout << "Сжатый размер: ~" << compressedSize << " бит (12 бит/код)" << endl;
    cout << "Коэффициент сжатия: " << (float)originalSize / compressedSize << endl;
    cout << "Количество кодов: " << encoded.size() << endl;
    
    return 0;
}
```


#### Преимущества и недостатки LZW

**Преимущества:**

- Не требует передачи словаря (декодер строит его самостоятельно)
- Хорошо сжимает тексты с повторяющимися фразами
- Быстрый алгоритм

**Недостатки:**

- Словарь может расти очень большим (нужны ограничения)
- Не всегда эффективен на коротких данных
- Патентные ограничения (сейчас патенты истекли)

**Применение:**

- GIF (формат изображений)
- TIFF (некоторые варианты)
- Старые версии Unix compress

***

## Глава 4: Помехоустойчивое кодирование

Теперь перейдём к совершенно другой задаче: как защитить информацию от ошибок при передаче по ненадёжному каналу?

### 4.1 Введение в помехоустойчивое кодирование

Представьте, что вы отправляете по радио двоичное сообщение: `10110`. Из-за помех приёмник может получить: `10010` (один бит испортился). Как обнаружить ошибку? Как её исправить?

**Основная идея:** Добавляем **избыточную информацию** специальным образом, чтобы даже при искажении части данных можно было восстановить исходное сообщение.

**Типы кодов:**

1. **Обнаруживающие ошибки** — позволяют определить, что произошла ошибка
2. **Исправляющие ошибки** — позволяют не только обнаружить, но и исправить ошибки

**Основные понятия:**

- **Кодовое слово** — последовательность битов после добавления избыточности
- **Расстояние Хэмминга** — количество позиций, в которых два слова отличаются
- **Минимальное кодовое расстояние** — минимальное расстояние между любыми двумя кодовыми словами

**Теорема:** Чтобы обнаружить $d$ ошибок, нужно минимальное расстояние $d + 1$. Чтобы исправить $t$ ошибок, нужно минимальное расстояние $2t + 1$.

### 4.2 Простейший пример: бит чётности

Самый простой помехоустойчивый код — **бит чётности**.

**Алгоритм:**

1. Считаем количество единиц в данных
2. Добавляем бит так, чтобы общее количество единиц стало чётным (или нечётным — зависит от варианта)

**Пример:**

Данные: `1011` (три единицы — нечётное число)
Добавляем бит чётности: `1` (чтобы стало 4 единицы — чётное)
Кодовое слово: `10111`

Если при передаче произошла ошибка в одном бите:
Получено: `10011` (две единицы — чётное... стоп! Что-то не так!)

Мы обнаружили ошибку! Но не знаем, где именно.

**Реализация на C++:**

```cpp
#include <iostream>
#include <bitset>

using namespace std;

// Функция вычисления бита чётности
bool calculateParityBit(const bitset<8>& data) {
    int onesCount = data.count();  // Считаем количество единиц
    return (onesCount % 2 == 1);    // Возвращаем 1, если нечётное количество
}

// Функция проверки бита чётности
bool checkParity(const bitset<9>& dataWithParity) {
    int onesCount = dataWithParity.count();
    return (onesCount % 2 == 0);  // Должно быть чётное количество
}

int main() {
    // Исходные данные (8 бит)
    bitset<8> data("10110101");
    
    cout << "Исходные данные: " << data << endl;
    cout << "Количество единиц: " << data.count() << endl;
    
    // Вычисляем бит чётности
    bool parityBit = calculateParityBit(data);
    cout << "Бит чётности: " << parityBit << endl;
    
    // Формируем кодовое слово
    bitset<9> encoded;
    for (int i = 0; i < 8; i++) {
        encoded[i] = data[i];
    }
    encoded[^8] = parityBit;
    
    cout << "Кодовое слово: " << encoded << endl;
    
    // Проверяем корректность
    if (checkParity(encoded)) {
        cout << "✓ Проверка чётности пройдена" << endl;
    } else {
        cout << "✗ Ошибка чётности!" << endl;
    }
    
    // Симулируем ошибку
    bitset<9> corrupted = encoded;
    corrupted.flip(3);  // Инвертируем 3-й бит
    
    cout << "\nПосле ошибки: " << corrupted << endl;
    
    if (checkParity(corrupted)) {
        cout << "✓ Проверка чётности пройдена" << endl;
    } else {
        cout << "✗ Ошибка обнаружена!" << endl;
    }
    
    return 0;
}
```

**Ограничения:**

- Обнаруживает только **нечётное** количество ошибок (1, 3, 5...)
- Не может исправить ошибки
- Не обнаруживает две одновременные ошибки


### 4.3 Код Хэмминга

Ричард Хэмминг в 1950 году придумал элегантный способ не только обнаруживать, но и **исправлять одиночные ошибки**.

#### Теория кода Хэмминга

**Основная идея:** Размещаем проверочные биты на позициях, являющихся степенями двойки (1, 2, 4, 8, 16...). Каждый проверочный бит контролирует определённые позиции данных.

**Для кода Хэмминга (7,4):**

- 4 информационных бита
- 3 проверочных бита
- 7 бит всего

**Расположение битов:**

```
Позиция:    1   2   3   4   5   6   7
Тип:        P1  P2  D1  P4  D2  D3  D4
```

Где:

- P1, P2, P4 — проверочные биты
- D1, D2, D3, D4 — информационные биты

**Какие биты контролирует каждый проверочный бит?**

Это определяется двоичным представлением номера позиции:

- **P1 (позиция 1 = 001₂)** контролирует позиции, где младший бит = 1: 1, 3, 5, 7
- **P2 (позиция 2 = 010₂)** контролирует позиции, где средний бит = 1: 2, 3, 6, 7
- **P4 (позиция 4 = 100₂)** контролирует позиции, где старший бит = 1: 4, 5, 6, 7

**Таблица контроля:**


| Проверочный бит | Контролирует позиции |
| :-- | :-- |
| P1 | 1, 3, 5, 7 |
| P2 | 2, 3, 6, 7 |
| P4 | 4, 5, 6, 7 |

#### Алгоритм кодирования

**Шаг 1:** Размещаем информационные биты на позициях, не являющихся степенями двойки.

Например, кодируем данные `D1 D2 D3 D4 = 1011`:

```
Позиция:    1   2   3   4   5   6   7
Биты:       P1  P2  1   P4  0   1   1
```

**Шаг 2:** Вычисляем проверочные биты:

**P1** контролирует позиции 1, 3, 5, 7:

- Позиция 3: `1`
- Позиция 5: `0`
- Позиция 7: `1`
- Сумма: 1 + 0 + 1 = 2 (чётное)
- **P1 = 0** (чтобы сумма всех контролируемых битов была чётной)

**P2** контролирует позиции 2, 3, 6, 7:

- Позиция 3: `1`
- Позиция 6: `1`
- Позиция 7: `1`
- Сумма: 1 + 1 + 1 = 3 (нечётное)
- **P2 = 1** (чтобы сумма стала чётной: 1 + 1 + 1 + 1 = 4)

**P4** контролирует позиции 4, 5, 6, 7:

- Позиция 5: `0`
- Позиция 6: `1`
- Позиция 7: `1`
- Сумма: 0 + 1 + 1 = 2 (чётное)
- **P4 = 0**

**Итоговое кодовое слово:**

```
Позиция:    1   2   3   4   5   6   7
Биты:       0   1   1   0   0   1   1
```


#### Алгоритм декодирования и исправления ошибок

**Шаг 1:** Вычисляем синдром ошибки — проверяем каждый проверочный бит:

**S1** (проверка P1): Суммируем биты на позициях 1, 3, 5, 7 по модулю 2
**S2** (проверка P2): Суммируем биты на позициях 2, 3, 6, 7 по модулю 2
**S4** (проверка P4): Суммируем биты на позициях 4, 5, 6, 7 по модулю 2

**Шаг 2:** Синдром `S = S4 S2 S1` указывает на позицию ошибки:

- Если `S = 000` — ошибок нет
- Если `S ≠ 000` — ошибка в позиции с номером S (в двоичной системе)

**Пример:** Пусть при передаче исказился бит на позиции 5:

Отправлено: `0110011`
Получено: `0110111` (бит 5 изменился с 0 на 1)

Проверяем:

- **S1** (позиции 1,3,5,7): 0 + 1 + 1 + 1 = 3 (нечётное) → S1 = 1
- **S2** (позиции 2,3,6,7): 1 + 1 + 1 + 1 = 4 (чётное) → S2 = 0
- **S4** (позиции 4,5,6,7): 0 + 1 + 1 + 1 = 3 (нечётное) → S4 = 1

Синдром: S = 101₂ = 5₁₀

**Ошибка на позиции 5!** Исправляем, инвертируя бит: `0110111` → `0110011`

#### Реализация кода Хэмминга (7,4) на C++

```cpp
#include <iostream>
#include <bitset>
#include <vector>

using namespace std;

// Класс для кода Хэмминга (7,4)
class HammingCode_7_4 {
private:
    // Функция проверки чётности для заданных позиций
    bool checkParity(const bitset<7>& data, const vector<int>& positions) {
        int sum = 0;
        for (int pos : positions) {
            // Позиции в алгоритме нумеруются с 1, в bitset — с 0
            sum += data[pos - 1];
        }
        return (sum % 2 == 0);  // Возвращаем true, если чётность соблюдена
    }
    
public:
    // Функция кодирования 4 информационных бит
    bitset<7> encode(const bitset<4>& data) {
        bitset<7> encoded;
        
        // Размещаем информационные биты
        encoded[^2] = data[^0];  // D1 → позиция 3
        encoded[^4] = data[^1];  // D2 → позиция 5
        encoded[^5] = data[^2];  // D3 → позиция 6
        encoded[^6] = data[^3];  // D4 → позиция 7
        
        // Вычисляем проверочные биты
        
        // P1 (позиция 1) контролирует позиции 1, 3, 5, 7
        int p1 = encoded[^2] ^ encoded[^4] ^ encoded[^6];  // XOR битов 3, 5, 7
        encoded[^0] = p1;
        
        // P2 (позиция 2) контролирует позиции 2, 3, 6, 7
        int p2 = encoded[^2] ^ encoded[^5] ^ encoded[^6];  // XOR битов 3, 6, 7
        encoded[^1] = p2;
        
        // P4 (позиция 4) контролирует позиции 4, 5, 6, 7
        int p4 = encoded[^4] ^ encoded[^5] ^ encoded[^6];  // XOR битов 5, 6, 7
        encoded[^3] = p4;
        
        return encoded;
    }
    
    // Функция декодирования и исправления ошибок
    pair<bitset<4>, int> decode(bitset<7> received) {
        // Вычисляем синдром ошибки
        
        // S1: проверка P1 (позиции 1, 3, 5, 7)
        int s1 = received[^0] ^ received[^2] ^ received[^4] ^ received[^6];
        
        // S2: проверка P2 (позиции 2, 3, 6, 7)
        int s2 = received[^1] ^ received[^2] ^ received[^5] ^ received[^6];
        
        // S4: проверка P4 (позиции 4, 5, 6, 7)
        int s4 = received[^3] ^ received[^4] ^ received[^5] ^ received[^6];
        
        // Формируем синдром
        int syndrome = s4 * 4 + s2 * 2 + s1;
        
        // Если синдром не нулевой, исправляем ошибку
        if (syndrome != 0) {
            cout << "Обнаружена ошибка на позиции " << syndrome << endl;
            received.flip(syndrome - 1);  // Исправляем бит (позиции с 1, в bitset с 0)
        }
        
        // Извлекаем информационные биты
        bitset<4> data;
        data[^0] = received[^2];  // D1 с позиции 3
        data[^1] = received[^4];  // D2 с позиции 5
        data[^2] = received[^5];  // D3 с позиции 6
        data[^3] = received[^6];  // D4 с позиции 7
        
        return {data, syndrome};
    }
    
    // Вспомогательная функция вывода битов с номерами позиций
    void printWithPositions(const bitset<7>& bits) {
        cout << "Позиция: ";
        for (int i = 7; i >= 1; i--) {
            cout << i << " ";
        }
        cout << endl;
        
        cout << "Биты:    ";
        for (int i = 6; i >= 0; i--) {
            cout << bits[i] << " ";
        }
        cout << endl;
        
        cout << "Тип:     ";
        for (int i = 7; i >= 1; i--) {
            if (i == 1 || i == 2 || i == 4) {
                cout << "P ";
            } else {
                cout << "D ";
            }
        }
        cout << endl;
    }
};

// Демонстрация работы
int main() {
    HammingCode_7_4 hamming;
    
    // Исходные данные (4 бита)
    bitset<4> original("1011");
    
    cout << "Исходные данные (4 бита): " << original << endl;
    cout << "D1=" << original[^0] << " D2=" << original[^1] 
         << " D3=" << original[^2] << " D4=" << original[^3] << endl;
    
    // Кодируем
    bitset<7> encoded = hamming.encode(original);
    cout << "\nКодовое слово (7 бит): " << encoded << endl;
    hamming.printWithPositions(encoded);
    
    // Декодируем без ошибок
    cout << "\n--- Декодирование без ошибок ---" << endl;
    auto [decoded1, syndrome1] = hamming.decode(encoded);
    if (syndrome1 == 0) {
        cout << "✓ Ошибок не обнаружено" << endl;
    }
    cout << "Декодированные данные: " << decoded1 << endl;
    
    // Симулируем ошибку на позиции 5
    cout << "\n--- Симуляция ошибки на позиции 5 ---" << endl;
    bitset<7> corrupted = encoded;
    corrupted.flip(4);  // Позиция 5 → индекс 4
    
    cout << "Искажённое кодовое слово: " << corrupted << endl;
    hamming.printWithPositions(corrupted);
    
    // Декодируем с исправлением
    auto [decoded2, syndrome2] = hamming.decode(corrupted);
    cout << "Синдром: " << syndrome2 << endl;
    cout << "Декодированные данные: " << decoded2 << endl;
    
    // Проверяем корректность исправления
    if (decoded2 == original) {
        cout << "✓ Ошибка успешно исправлена!" << endl;
    } else {
        cout << "✗ Ошибка исправления!" << endl;
    }
    
    // Симулируем две ошибки (код не сможет исправить)
    cout << "\n--- Симуляция двух ошибок (позиции 3 и 5) ---" << endl;
    bitset<7> doubleError = encoded;
    doubleError.flip(2);  // Позиция 3
    doubleError.flip(4);  // Позиция 5
    
    cout << "Искажённое кодовое слово: " << doubleError << endl;
    
    auto [decoded3, syndrome3] = hamming.decode(doubleError);
    cout << "Синдром: " << syndrome3 << endl;
    cout << "Декодированные данные: " << decoded3 << endl;
    
    if (decoded3 == original) {
        cout << "✓ Данные корректны" << endl;
    } else {
        cout << "✗ Код Хэмминга (7,4) не может исправить 2 ошибки" << endl;
    }
    
    return 0;
}
```


#### Расширенный код Хэмминга (8,4)

Для увеличения надёжности к коду Хэмминга (7,4) добавляют ещё один бит — **общий бит чётности**, контролирующий все 8 бит. Это позволяет:

- Исправлять 1 ошибку
- Обнаруживать 2 ошибки

**Логика:**

- Если синдром = 0 и общая чётность правильная → нет ошибок
- Если синдром ≠ 0 и общая чётность неправильная → 1 ошибка (исправляем)
- Если синдром ≠ 0 и общая чётность правильная → 2 ошибки (обнаруживаем, но не исправляем)


### 4.4 Коды Рида-Соломона

Коды Рида-Соломона — это мощные коды, способные исправлять **пакеты ошибок** (когда искажаются подряд несколько битов). Они используются повсеместно:

- CD, DVD, Blu-ray
- QR-коды
- Космическая связь
- Цифровое телевидение
- Сети передачи данных


#### Теория

Коды Рида-Соломона работают не с отдельными битами, а с **символами** (обычно 8-битными байтами). Они основаны на алгебре конечных полей (полей Галуа).

**Основные параметры:**

- $n$ — длина кодового слова (количество символов)
- $k$ — количество информационных символов
- $n - k = 2t$ — количество проверочных символов, где $t$ — количество ошибок, которые можно исправить

**Например, код RS(255, 223):**

- 223 информационных байта
- 32 проверочных байта
- Может исправить до 16 ошибочных байтов


#### Принцип работы

Представим сообщение как **полином**. Например, сообщение `` представляется как:

$$
M(x) = 3x^3 + 1x^2 + 4x + 1
$$

**Кодирование:**

1. Умножаем $M(x)$ на $x^{2t}$ (сдвигаем, освобождая место для проверочных символов)
2. Делим результат на порождающий полином $G(x)$
3. Остаток от деления — это проверочные символы
4. Кодовое слово: исходные данные + остаток

**Декодирование:**

1. Вычисляем синдромы (проверяем, делится ли полученное слово на $G(x)$)
2. Если синдромы не нулевые, находим позиции и значения ошибок
3. Исправляем ошибки

#### Упрощённая реализация на C++

Полная реализация кодов Рида-Соломона требует арифметики конечных полей и выходит за рамки учебного материала. Вот концептуальный пример:

```cpp
#include <iostream>
#include <vector>

using namespace std;

// Примечание: Это сильно упрощённая демонстрация концепции!
// Реальная реализация требует библиотеки для работы с полями Галуа.

class ReedSolomonSimple {
private:
    int n;  // Длина кодового слова
    int k;  // Количество информационных символов
    int t;  // Количество исправляемых ошибок
    
public:
    ReedSolomonSimple(int codewordLength, int dataLength) 
        : n(codewordLength), k(dataLength) {
        t = (n - k) / 2;
    }
    
    // Упрощённая функция кодирования (концептуальная)
    vector<int> encode(const vector<int>& data) {
        if (data.size() != k) {
            cerr << "Ошибка: размер данных должен быть " << k << endl;
            return {};
        }
        
        vector<int> codeword(n);
        
        // Копируем информационные символы
        for (int i = 0; i < k; i++) {
            codeword[i] = data[i];
        }
        
        // Вычисляем проверочные символы (сильно упрощено!)
        // В реальности здесь происходит деление полиномов в GF(2^m)
        for (int i = k; i < n; i++) {
            int checksum = 0;
            for (int j = 0; j < k; j++) {
                checksum ^= data[j];  // XOR как простейшая "проверка"
            }
            codeword[i] = checksum % 256;
        }
        
        cout << "Кодирование: " << k << " информационных символов → " 
             << n << " символов кодового слова" << endl;
        cout << "Можно исправить до " << t << " ошибок" << endl;
        
        return codeword;
    }
    
    // Упрощённая функция декодирования
    vector<int> decode(const vector<int>& received) {
        cout << "\nДекодирование..." << endl;
        
        // В реальности здесь:
        // 1. Вычисление синдромов
        // 2. Алгоритм Берлекампа-Месси для нахождения локатора ошибок
        // 3. Алгоритм Ченя для нахождения позиций ошибок
        // 4. Вычисление значений ошибок
        // 5. Исправление
        
        cout << "Проверка синдромов..." << endl;
        
        // Упрощённая проверка
        bool hasError = false;
        for (int i = k; i < n; i++) {
            int checksum = 0;
            for (int j = 0; j < k; j++) {
                checksum ^= received[j];
            }
            if (received[i] != checksum % 256) {
                hasError = true;
                break;
            }
        }
        
        if (hasError) {
            cout << "Обнаружены ошибки. Попытка исправления..." << endl;
            // Реальный алгоритм исправления здесь
        } else {
            cout << "✓ Ошибок не обнаружено" << endl;
        }
        
        // Извлекаем информационные символы
        vector<int> data(k);
        for (int i = 0; i < k; i++) {
            data[i] = received[i];
        }
        
        return data;
    }
    
    void printCodeword(const vector<int>& codeword) {
        cout << "Кодовое слово: [";
        for (size_t i = 0; i < codeword.size(); i++) {
            cout << codeword[i];
            if (i < codeword.size() - 1) cout << ", ";
        }
        cout << "]" << endl;
    }
};

int main() {
    // Создаём кодер RS(10, 6) — простой пример
    // 6 информационных символов, 4 проверочных (может исправить 2 ошибки)
    ReedSolomonSimple rs(10, 6);
    
    // Исходные данные
    vector<int> data = {10, 20, 30, 40, 50, 60};
    
    cout << "Исходные данные: ";
    for (int d : data) cout << d << " ";
    cout << endl;
    
    // Кодируем
    vector<int> encoded = rs.encode(data);
    rs.printCodeword(encoded);
    
    // Декодируем без ошибок
    cout << "\n--- Декодирование без ошибок ---" << endl;
    vector<int> decoded1 = rs.decode(encoded);
    
    // Симулируем ошибки
    cout << "\n--- Симуляция ошибок ---" << endl;
    vector<int> corrupted = encoded;
    corrupted[^2] = 99;   // Ошибка в позиции 2
    corrupted[^7] = 123;  // Ошибка в позиции 7
    
    cout << "Искажённое кодовое слово: ";
    rs.printCodeword(corrupted);
    
    vector<int> decoded2 = rs.decode(corrupted);
    
    cout << "\n! Примечание: Это упрощённая демонстрация концепции." << endl;
    cout << "Реальная реализация RS требует библиотек для арифметики" << endl;
    cout << "конечных полей (например, libcorrect, libfec)." << endl;
    
    return 0;
}
```


#### Применение кодов Рида-Соломона

**QR-коды:**
QR-коды используют RS для защиты от повреждений. Даже если часть кода стёрта или загрязнена, информацию можно восстановить.

**Уровни коррекции в QR:**

- Level L: восстанавливает ~7% данных
- Level M: ~15%
- Level Q: ~25%
- Level H: ~30%

**Космическая связь:**
Сигналы с космических аппаратов очень слабые и подвержены помехам. RS-коды позволяют надёжно передавать данные на миллионы километров.

***

## Глава 5: Кодирование с потерями

Теперь перейдём к алгоритмам, которые жертвуют точностью ради радикального уменьшения размера. Это используется для мультимедиа: изображений, аудио, видео.

### 5.1 Основные принципы

**Зачем нужно сжатие с потерями?**

Человеческое восприятие несовершенно. Мы не видим все цвета, не слышим все частоты. Зачем хранить информацию, которую мы всё равно не замечаем?

**Примеры:**

- Человек не слышит звуки выше 20 кГц — можно их удалить
- Глаз плохо различает мелкие детали в тени — можно их огрубить
- Быстрое движение в видео размывается — можно передавать меньше деталей

**Основные техники:**

1. **Трансформация** — перевод в другое пространство (частотное, вейвлет-преобразование)
2. **Квантование** — округление значений, уменьшение точности
3. **Прореживание** — снижение разрешения, частоты дискретизации



